{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "class perceptron:\n",
    "    def __init__(self, weights:list, bias=0, output:bool=False) -> None:\n",
    "        self.bias = bias\n",
    "        self.weights = weights\n",
    "        self.output = output\n",
    "        self.activity = 0\n",
    "        self.activation = 0\n",
    "        self.d_weights = weights.copy() # shouldn't use before it gets set\n",
    "        self.d_bias = 0\n",
    "        self.delta = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.calculate_activity(x)\n",
    "        return self.calculate_activation()\n",
    "\n",
    "    def calculate_activity(self, inputs:list):\n",
    "        # A_j = sum(w_ij * x_i) + bias\n",
    "        total = self.bias\n",
    "        for x in range(len(inputs)):\n",
    "            total += inputs[x] * self.weights[x]\n",
    "        self.activity = total\n",
    "        return total\n",
    "    \n",
    "    def calculate_activation(self):\n",
    "        # y_j = f(A_j) -- using sigmoid\n",
    "        self.activation = 1 / (1 + math.exp(self.activity * -1))\n",
    "        return self.activation\n",
    "\n",
    "    def calculate_delta_w(self, x, eta, expected=None, dk_w=None):\n",
    "        # delta_w = eta * (d_k * x_j)\n",
    "        # d_k = e_k (1-y)y\n",
    "        if(self.output):\n",
    "            self.delta = (expected - self.activation) * (1-self.activation) * self.activation\n",
    "        else:\n",
    "            self.delta = (1 - self.activation) * self.activation * (dk_w)\n",
    "        for i in range(len(x)):\n",
    "            self.d_weights[i] = eta * self.delta * x[i]\n",
    "        self.d_bias = eta * self.delta\n",
    "        return self.delta, self.d_weights\n",
    "\n",
    "    def calculate_previous_d(self):\n",
    "        prevs = []\n",
    "        for weight in self.weights:\n",
    "            prevs.append(weight*self.delta)\n",
    "        return prevs\n",
    "\n",
    "    def update_weights(self, bias=True):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] = self.weights[i] + self.d_weights[i]\n",
    "        if bias: self.bias = self.bias + self.d_bias\n",
    "        return self.weights\n",
    "    \n",
    "    def compute_error(self, expected):\n",
    "        e = ((expected - self.activation) ** 2) / 2\n",
    "        return e\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return self.weights, self.bias\n",
    "\n",
    "class layer:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post-1: n3 activation: 0.6583208713508027, error: 0.029204400612317622\n",
      "post-2: n3 activation: 0.3817659623378531, error: 0.055034326882980884\n",
      "Node 3 weights: ([0.9518579656080158, 0.9518579656080158], -0.8257813486188029)\n"
     ]
    }
   ],
   "source": [
    "iterations = 15\n",
    "x1 = [1,1]\n",
    "x2 = [-1,-1]\n",
    "expected_1 = .9\n",
    "expected_2 = .05\n",
    "eta = 1\n",
    "# initial weights\n",
    "node1 = perceptron([.3,.3], bias=1, output=True)\n",
    "\n",
    "# Should be all needed for a single perceptron (aside from accounting for our data)\n",
    "for i in range(iterations):\n",
    "    node1.forward(x1)\n",
    "    node1.calculate_delta_w(x1, eta, expected_1)\n",
    "    node1.update_weights()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
